# Projeto MBA Engenharia de dados
## ConstruÃ§Ã£o de um Data Lakehouse Transacional




## ğŸ“‚ Estrutura do Projeto

```
/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ logistica_raw.csv       # Dataset bruto para ser utilizado no exercicio.
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ geradorDataset.ipynb    # Notebook Jupter com o codigo para Gerar o arquivo CSV para o Exercicio.
â”‚   â”œâ”€â”€ script.ipynb            # Notebook Jupyter com todo o cÃ³digo PySpark.
â”‚   â””â”€â”€ vendas_brutas.csv       # Dataset bruto utilizado no exemplo.
â”œâ”€â”€ docker-compose.yml          # Arquivo para orquestrar o ambiente Docker.
â”œâ”€â”€ Dockerfile                  # Arquivo de configuraÃ§Ã£o para a imagem Docker.
â”œâ”€â”€ exercicio.md                # Arquivo com o Desafio para ser feito em aula
â””â”€â”€ readme.md                   # Este arquivo.
```

## ğŸ› ï¸ Setup e ExecuÃ§Ã£o do Ambiente

Para executar o projeto, utilizamos um ambiente Docker que jÃ¡ contÃ©m o Jupyter e o PySpark configurados.

### PrÃ©-requisitos
*   [Docker](httpss://docs.docker.com/get-docker/)
*   [Docker Compose](httpss://docs.docker.com/compose/install/)

### Passos para ExecuÃ§Ã£o

1.  **Clone o RepositÃ³rio**:
    ```bash
    git clone 
    cd dataqualitySpark
    ```

2.  **Inicie o Ambiente Docker**:
    No terminal, a partir da raiz do projeto, execute o comando abaixo. Ele irÃ¡ construir a imagem Docker (se ainda nÃ£o existir) e iniciar o container do JupyterLab em background.
    ```bash
    docker compose up --build -d
    ```

3.  **Acesse o Jupyter**:
    Abra seu navegador e acesse o seguinte endereÃ§o:
    ```
    http://localhost:8888/
    ```
    *   O token de acesso jÃ¡ estÃ¡ configurado no `docker-compose.yml` para simplificar.
